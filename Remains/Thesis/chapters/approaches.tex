\chapter{Approaches}
\lhead{ \thechapter \space Approaches}
\label{ch:approaches}
This chapter covers the research done on potentially feasible \gls{AI}-based approaches.

\section{Multi-Objective Deep Q Networks with Subsumption Architecture}
Originally described by Rodney Brooks, it could be considered the opposition of \gls{AI}. This is due to the fact that subsumption architecture makes use of sensory input to layer competences, instead of being guided by mental/behavioral-based algorithms like \gls{AI} algorithms typically are \citep{subsumption_architecture}.
\\\\
A paper by Tomasz Tajmajer describes a solution that combines a multi-objective \gls{DQN} with signal suppression known from subsumption architecture to control a floor cleaning robot in a physical environment. As the paper explains, it makes use of separate \gls{DQN}s (A deep learned form of reinforcement learning) to determine the next action for each of the sub-tasks (floor cleaning, collision avoidance, recharging), which then get combined into one singular output that determines the next action. To create a single output, however, signal suppression is used to create a hierarchy among sub-tasks. For example, if the cleaning robot were to simultaneously have to avoid collision and recharge, it would most likely end up in it colliding as one task commands the robot the move and the other commands it to halt. To avoid this, the collision avoidance task is able to suppress the recharge task in order for the robot to prioritize its safety first \citep{mdqns}. This approach could be used for this project, where example sub-tasks could be collision avoidance and moving to a location.

\section{Object Detection-Based}
\label{sec:ssd_segmentation}
\gls{SSD} is a method that uses a convolutional neural network to detect objects in a single frame. Its detection speeds are very high, making it very suitable for real-time detection \citep{ssd}. An approach could be to train an \gls{SSD} to detect common objects that the drone needs to avoid. As the sizes of the objects are known roughly, a distance estimation can be made based on the pixel size. Alternatively, a \gls{RCNN} can be used. As the name suggests, it differs from a regular convolutional neural network in the way that it adds another layer to the Faster \gls{RCNN} model that creates a segmentation mask around the object in the bounding box, without the significant loss of performance (real-time speed of 5 frames per second) \citep{mask_cnn}. Just like the Faster-\gls{RCNN} it is based on, it makes use of Region Proposal Network that creates rectangles around potential objects and scores them based on their membership to object classes vs. the background \citep{faster_rcnn}. A project by Waleed Abdulla presents an implementation of a Mask \gls{RCNN} \citep{matterport}, which could then be used to estimate the distance with. While the distance estimation would be more accurate with the latter approach, it comes at the price of a drop in processing speed and thus frame rate.

\section{Unity Machine Learning Agents}
\label{sec:approach_ml_agents}
\gls{unity} is an open-source game engine used for creating 2D and 3D games/simulations. In 2017, Unity introduced a toolkit called \gls{mlagents}, which enables users to use reinforcement learning on their Unity environments \citep{mlagents_blog, mlagents_paper}. The approach would then be to create a somewhat realistic simulation of a warehouse to train an algorithm on, and then later use the trained algorithm on a real drone. An example of this would be the solution presented by Adam Kelly, who created a simulation for training airplanes to fly through waypoints \citep{ai_flight}.
\\\\
An alternative approach could be to make use of imitation learning instead of regular reinforcement learning to train the algorithm. At a Unity event called Unite, Unity gave a number of demonstrations of \gls{mlagents} applications. Among these demonstrations was a racing game, where the algorithm learned to copy the human player's behavior through imitation learning \citep{imitation_learning, mlagents_paper}. This could be used to learn the drone to autonomously fly to certain points in the warehouse while avoiding collisions.
